{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lOpHgdhy_GWA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # 生成 20 个股票代码\n",
        "# rics = [f'{str(i).zfill(4)}.HK' for i in range(1, 20)]\n",
        "\n",
        "# # 生成日期范围\n",
        "# dates = pd.date_range(start='2022-12-01', end='2022-12-30').strftime('%Y-%m-%d')\n",
        "\n",
        "# # 生成时间范围\n",
        "# times = np.linspace(34200.0000, 42600.0000, 1400)\n",
        "\n",
        "# # 生成特征列名\n",
        "# columns = ['s1_a1_down_b1_down', 's1_a1_rise_amt_d_all', 's1_a1_up_b1_down', 's1_amt_ms', 's1_ask3_amt_pct',\n",
        "#            's1_ask_pct', 's1_ave_ab_diff', 's1_b10da10_mean', 's1_b1_down_amt_d_all', 's1_bda1_rdd_amt',\n",
        "#            's1_bda_med', 's1_bdatn_med', 's1_bid_p_std', 's1_bma_3_pct', 's1_bma_chg', 's1_corr_pt', 's1_corr_pv',\n",
        "#            's1_dtb_d_a_std', 's1_dtb_d_amt', 's1_hl_t_diff', 's1_mid_up_mid3_v', 's1_near_btd_rate',\n",
        "#            's1_px_chg_abs_sum', 's1_px_chg_skew', 's1_px_chg_std', 's1_px_up_ma5', 's1_rise_vwap', 's1_ta_d_a',\n",
        "#            's1_vdt', 's1_vwap_up_lastmid', 's1_vwap_up_mid', 's1_vwap_up_mid3_v', 's5_a1_rise_amt_d_all',\n",
        "#            's5_amt_compare', 's5_amt_max_pct', 's5_a_sk3_amt_pct', 's5_ask_10d3_d1', 's5_ask_10d3_max',\n",
        "#            's5_b10da10_mean', 's5_b1d10_up_ask10_down', 's5_bid_p_std', 's5_hl1_d4', 's5_high2last',\n",
        "#            's5_last_avea_corr', 's5_low2last', 's5_max5_rise_sum', 's5_mid_up_mid3_v', 's5_near_btd3_rate',\n",
        "#            's5_near_btd_rate', 's5_pct_chg_max', 's5_pct_ud', 's5_px_chg_abs_sum', 's5_px_chg_skew', 's5_px_chg_std',\n",
        "#            's5_rise_vwap', 's5_rise_wap', 's5_rise_wapd_ms', 's5_v2hl_std', 's5_v5vdv', 's5_vol_d_ab10_diff',\n",
        "#            's5_vol_d_corr', 's5_vw_pct', 's5_vw_px_vwap_diff', 's5_vwap_1d5', 's5_warm_rise', 's_ask_pct',\n",
        "#            's_b1_down_amt_d_all', 's_bda1_rdd_amt_rate', 's_bid3_amt_pct', 's_bma_3_pct', 's_cavity',\n",
        "#            's_et_rd_num_diff', 's_high2last', 's_high_when', 's_hspread_rise', 's_low2last', 's_low_when',\n",
        "#            's_max_draw', 's_mid_up_mid3_v', 's_price2b', 's_price2wap', 's_price2wap_mean', 's_real_pct',\n",
        "#            's_spread_1d5', 's_std_ud', 's_trigger_time', 's_vexity', 's_vw_av_pct_diff', 's_vw_pct',\n",
        "#            's_vw_px_vwap_diff', 's_vwap_up_lastmid3_v', 's_vwap_up_mid', 's_vwap_up_mid3', '600','1800','3600','EOD','1800_.HSI','EOD_.HSI']\n",
        "\n",
        "# index = pd.MultiIndex.from_product([rics, dates, times], names=['RIC', 'DATE', 'TIME'])\n",
        "\n",
        "# data = np.random.randn(len(index), len(columns))\n",
        "\n",
        "# # 创建 DataFrame\n",
        "# df = pd.DataFrame(data, index=index, columns=columns)\n",
        "\n",
        "# df.to_parquet('./table_df.parquet')\n",
        "\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # 生成日期范围\n",
        "# dates = pd.date_range(start='2022-12-01', end='2022-12-30')\n",
        "\n",
        "# # 生成股票代码列表\n",
        "# rics = [f'{str(i).zfill(4)}.HK' for i in range(1, 20)]\n",
        "\n",
        "# data = []\n",
        "# for date in dates:\n",
        "#     # 每天随机选择 5 个股票代码\n",
        "#     selected_rics = np.random.choice(rics, 5, replace=False)\n",
        "#     # 生成权重，确保权重总和为 1\n",
        "#     weights = np.random.rand(5)\n",
        "#     weights = weights / weights.sum()\n",
        "#     for ric, weight in zip(selected_rics, weights):\n",
        "#         data.append([ric, date.strftime('%Y-%m-%d'), weight])\n",
        "\n",
        "# # 创建 DataFrame\n",
        "# constitute = pd.DataFrame(data, columns=['RIC', 'DATE', 'WEIGHT'])\n",
        "\n",
        "# constitute.to_parquet('./constitute.parquet')"
      ],
      "metadata": {
        "id": "HkH7Wb4P_J5K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class table:\n",
        "    df = pd.read_parquet('./table_df.parquet')\n",
        "constitute =  pd.read_parquet('./constitute.parquet')"
      ],
      "metadata": {
        "id": "4hLwrAay_OLM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## masked_df\n",
        "constitute_df = table.df.reset_index('TIME').merge(constitute.set_index(['RIC','DATE'])[['WEIGHT']], left_index=True, right_index = True, how='right').reset_index().set_index(['RIC','DATE','TIME'])"
      ],
      "metadata": {
        "id": "5W4BDUNj_d-R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "oBT9o8p4_fB8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPNetwork(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self, input_size: int, hidden_size: List[int], dropout_rate: float, act_fn: str = \"elu\", bn: bool = False\n",
        "    ) -> None:\n",
        "        super(MLPNetwork, self).__init__()\n",
        "        layers = []\n",
        "        input_dim = input_size\n",
        "        for i, hidden in enumerate(hidden_size):\n",
        "            layers.append(tf.keras.layers.Dense(hidden, name=f\"Dense_{i + 1}\"))\n",
        "            if act_fn is not None:\n",
        "                layers.append(tf.keras.layers.Activation(act_fn, name=f\"{act_fn}_{i + 1}\"))\n",
        "            if bn:\n",
        "                layers.append(tf.keras.layers.BatchNormalization(name=f\"BN_{i + 1}\"))\n",
        "            if dropout_rate > 0:\n",
        "                layers.append(tf.keras.layers.Dropout(dropout_rate, name=f\"Drop_{i + 1}\"))\n",
        "            input_dim = hidden\n",
        "\n",
        "        self.layer = tf.keras.Sequential(layers)\n",
        "        self.output_layer = tf.keras.layers.Dense(1, name=\"Output_Dense\")\n",
        "        self.get_last_hidden = False\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.layer(x)\n",
        "        if self.get_last_hidden:\n",
        "            return x\n",
        "        return tf.squeeze(self.output_layer(x), axis=-1)"
      ],
      "metadata": {
        "id": "yHVlIJIV_jSh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_tf_dataset_variable_stocks_slow(train_df, features, time_index_name='TIMEID'):\n",
        "    # 确保排序\n",
        "    train_df.sort_values(by=['DATE', 'RIC', 'TIME'], inplace=True)\n",
        "    train_df['TIMEID'] = train_df.groupby(['DATE', 'RIC']).cumcount()\n",
        "    train_df.set_index(['DATE', 'RIC', time_index_name], inplace=True)\n",
        "\n",
        "    # print(train_df)\n",
        "\n",
        "    # 获取每天的数据\n",
        "    grouped = train_df.groupby('DATE')\n",
        "\n",
        "    def generator():\n",
        "        for date, group in grouped:\n",
        "            df_feat = group[features].reset_index()\n",
        "            df_target = group['target'].reset_index()\n",
        "\n",
        "            # pivot: RIC × TIME → features 或 target\n",
        "            X = df_feat.pivot(index='RIC', columns=time_index_name, values=features)\n",
        "            y = df_target.pivot(index='RIC', columns=time_index_name, values='target')\n",
        "\n",
        "            # 对时间排序，防止错位\n",
        "            X = X.sort_index(axis=1, level=time_index_name)\n",
        "            y = y.sort_index(axis=1)\n",
        "\n",
        "            # 还原成 3D：(num_stocks, T, F)\n",
        "            X_arr = X.values.reshape(len(X), -1, len(features))  # shape: (num_stocks, T, F)\n",
        "            y_arr = y.values  # shape: (num_stocks, T)\n",
        "\n",
        "            yield X_arr.astype(np.float32), y_arr.astype(np.float32)\n",
        "\n",
        "    # 获取单个样本的 shape 用于 tf spec（只看第一个 batch）\n",
        "    for x0, y0 in generator():\n",
        "        sample_shape_x = tf.TensorShape([None, x0.shape[1], x0.shape[2]])  # (num_stocks, T, F)\n",
        "        sample_shape_y = tf.TensorShape([None, y0.shape[1]])  # (num_stocks, T)\n",
        "        break\n",
        "\n",
        "    # 创建 tf.data.Dataset\n",
        "    output_signature = (\n",
        "        tf.TensorSpec(shape=sample_shape_x, dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=sample_shape_y, dtype=tf.float32),\n",
        "    )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature)\n"
      ],
      "metadata": {
        "id": "P4fbn5X9RzHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factor_all_df = table.df.reset_index()\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import early_stopping, LGBMRegressor as LGBMR\n",
        "import multiprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_tf_dataset_variable_stocks_flat(train_df, features, time_col='TIMEID'):\n",
        "    # 确保已排序，按日期、股票、时间顺序排列\n",
        "    train_df['TIMEID'] = train_df.groupby(['DATE', 'RIC']).cumcount()\n",
        "    train_df = train_df.sort_values(by=['DATE', 'RIC', time_col])\n",
        "    grouped = train_df.groupby('DATE')\n",
        "\n",
        "    def generator():\n",
        "        for date, group in grouped:\n",
        "            ric_list = group['RIC'].unique()\n",
        "            time_list = sorted(group[time_col].unique())  # 时间按顺序排列\n",
        "\n",
        "            ric_map = {ric: i for i, ric in enumerate(ric_list)}\n",
        "            time_map = {t: i for i, t in enumerate(time_list)}\n",
        "\n",
        "            num_ric = len(ric_list)\n",
        "            num_time = len(time_list)\n",
        "            num_feat = len(features)\n",
        "\n",
        "            # 初始化张量\n",
        "            X = np.full((num_ric, num_time, num_feat), np.nan, dtype=np.float32)\n",
        "            Y = np.full((num_ric, num_time), np.nan, dtype=np.float32)\n",
        "\n",
        "            # 填充数据\n",
        "            for _, row in group.iterrows():\n",
        "                i = ric_map[row['RIC']]\n",
        "                j = time_map[row[time_col]]\n",
        "                X[i, j, :] = row[features].values\n",
        "                Y[i, j] = row['target']\n",
        "\n",
        "            yield X, Y\n",
        "\n",
        "    # 获取一个 batch 推断 output_signature\n",
        "    for x0, y0 in generator():\n",
        "        x_shape = tf.TensorShape([None, x0.shape[1], x0.shape[2]])\n",
        "        y_shape = tf.TensorShape([None, y0.shape[1]])\n",
        "        break\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=x_shape, dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=y_shape, dtype=tf.float32)\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "factor_all_df['DATETIME'] = pd.to_datetime(factor_all_df['DATE'], format='%Y-%m-%d')\n",
        "pred_name = 'y_pred'\n",
        "\n",
        "features = ['s1_a1_down_b1_down', 's1_a1_rise_amt_d_all', 's1_a1_up_b1_down', 's1_amt_ms', 's1_ask3_amt_pct',\n",
        "           's1_ask_pct', 's1_ave_ab_diff', 's1_b10da10_mean', 's1_b1_down_amt_d_all', 's1_bda1_rdd_amt',\n",
        "           's1_bda_med', 's1_bdatn_med', 's1_bid_p_std', 's1_bma_3_pct', 's1_bma_chg', 's1_corr_pt', 's1_corr_pv',\n",
        "           's1_dtb_d_a_std', 's1_dtb_d_amt', 's1_hl_t_diff', 's1_mid_up_mid3_v', 's1_near_btd_rate',\n",
        "           's1_px_chg_abs_sum', 's1_px_chg_skew', 's1_px_chg_std', 's1_px_up_ma5', 's1_rise_vwap', 's1_ta_d_a',\n",
        "           's1_vdt', 's1_vwap_up_lastmid', 's1_vwap_up_mid', 's1_vwap_up_mid3_v', 's5_a1_rise_amt_d_all',\n",
        "           's5_amt_compare', 's5_amt_max_pct', 's5_a_sk3_amt_pct', 's5_ask_10d3_d1', 's5_ask_10d3_max',\n",
        "           's5_b10da10_mean', 's5_b1d10_up_ask10_down', 's5_bid_p_std', 's5_hl1_d4', 's5_high2last',\n",
        "           's5_last_avea_corr', 's5_low2last', 's5_max5_rise_sum', 's5_mid_up_mid3_v', 's5_near_btd3_rate',\n",
        "           's5_near_btd_rate', 's5_pct_chg_max', 's5_pct_ud', 's5_px_chg_abs_sum', 's5_px_chg_skew', 's5_px_chg_std',\n",
        "           's5_rise_vwap', 's5_rise_wap', 's5_rise_wapd_ms', 's5_v2hl_std', 's5_v5vdv', 's5_vol_d_ab10_diff',\n",
        "           's5_vol_d_corr', 's5_vw_pct', 's5_vw_px_vwap_diff', 's5_vwap_1d5', 's5_warm_rise', 's_ask_pct',\n",
        "           's_b1_down_amt_d_all', 's_bda1_rdd_amt_rate', 's_bid3_amt_pct', 's_bma_3_pct', 's_cavity',\n",
        "           's_et_rd_num_diff', 's_high2last', 's_high_when', 's_hspread_rise', 's_low2last', 's_low_when',\n",
        "           's_max_draw', 's_mid_up_mid3_v', 's_price2b', 's_price2wap', 's_price2wap_mean', 's_real_pct',\n",
        "           's_spread_1d5', 's_std_ud', 's_trigger_time', 's_vexity', 's_vw_av_pct_diff', 's_vw_pct',\n",
        "           's_vw_px_vwap_diff', 's_vwap_up_lastmid3_v', 's_vwap_up_mid', 's_vwap_up_mid3']\n",
        "\n",
        "factor_all_df['target'] =  (factor_all_df['1800_.HSI'])\n",
        "\n",
        "pred_name = 'y_pred' if pred_name is None else pred_name\n",
        "# # 划分训练集和测试集\n",
        "train_start = datetime(2022, 12, 1)\n",
        "train_end = datetime(2022, 12, 20)\n",
        "test_start = datetime(2022, 12, 20)\n",
        "test_end = datetime(2022, 12, 22)\n",
        "val_start = datetime(2022, 12, 22)\n",
        "val_end = datetime(2022, 12, 30)\n",
        "\n",
        "\n",
        "train_df = factor_all_df[(factor_all_df['DATETIME'] >= train_start) & (factor_all_df['DATETIME'] < train_end)]\n",
        "test1_df = factor_all_df[(factor_all_df['DATETIME'] >= test_start) & (factor_all_df['DATETIME'] < test_end)]\n",
        "test_df = factor_all_df[(factor_all_df['DATETIME'] >= val_start) & (factor_all_df['DATETIME'] < val_end)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_SimpleTSNN(X_train, y_train, X_test1, y_test1, X_test, y_test):\n",
        "  train_ds = create_tf_dataset_variable_stocks_flat(train_df, features)\n",
        "  test1_ds = create_tf_dataset_variable_stocks_flat(test1_df, features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # 在测试集上应用预测结果\n",
        "# train_df[pred_name] = (y_pred_train)\n",
        "# test_df[pred_name]  = (y_pred_test)"
      ],
      "metadata": {
        "id": "Ths2kcvj_lt0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CYZL_kjbDi-U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from typing import List\n",
        "\n",
        "# ============ 定义模型结构 ============\n",
        "class MLPNetwork(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self, input_size: int, hidden_size: List[int], dropout_rate: float, act_fn: str = \"elu\", bn: bool = False\n",
        "    ) -> None:\n",
        "        super(MLPNetwork, self).__init__()\n",
        "        layers = []\n",
        "        input_dim = input_size\n",
        "        for i, hidden in enumerate(hidden_size):\n",
        "            layers.append(tf.keras.layers.Dense(hidden, name=f\"Dense_{i + 1}\"))\n",
        "            if act_fn is not None:\n",
        "                layers.append(tf.keras.layers.Activation(act_fn, name=f\"{act_fn}_{i + 1}\"))\n",
        "            if bn:\n",
        "                layers.append(tf.keras.layers.BatchNormalization(name=f\"BN_{i + 1}\"))\n",
        "            if dropout_rate > 0:\n",
        "                layers.append(tf.keras.layers.Dropout(dropout_rate, name=f\"Drop_{i + 1}\"))\n",
        "            input_dim = hidden\n",
        "\n",
        "        self.layer = tf.keras.Sequential(layers)\n",
        "        self.output_layer = tf.keras.layers.Dense(1, name=\"Output_Dense\")\n",
        "        self.get_last_hidden = False\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.layer(x)\n",
        "        if self.get_last_hidden:\n",
        "            return x\n",
        "        return tf.squeeze(self.output_layer(x), axis=-1)\n",
        "\n",
        "# ============ 自定义相关系数损失函数（越大越好，因此返回负值） ============\n",
        "@tf.function\n",
        "def corr_loss(y_true, y_pred):\n",
        "    x = y_true - tf.reduce_mean(y_true)\n",
        "    y = y_pred - tf.reduce_mean(y_pred)\n",
        "    corr = tf.reduce_sum(x * y) / (tf.sqrt(tf.reduce_sum(x**2)) * tf.sqrt(tf.reduce_sum(y**2)) + 1e-8)\n",
        "    return -corr  # 越小越好 → 实际上是负相关系数\n",
        "\n",
        "# ============ 自定义信息比率指标 ============\n",
        "class InfoRatio(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='info_ratio', **kwargs):\n",
        "        super(InfoRatio, self).__init__(name=name, **kwargs)\n",
        "        self.returns = self.add_weight(name=\"returns\", shape=(0,), initializer=\"zeros\", dtype=tf.float32, aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # 模拟简单PnL（持仓 * 收益），可以更复杂地加权\n",
        "        returns = tf.reshape(y_pred * y_true, [-1])\n",
        "        self.returns.assign(tf.concat([self.returns, returns], axis=0))\n",
        "\n",
        "    def result(self):\n",
        "        mean_return = tf.reduce_mean(self.returns)\n",
        "        std_return = tf.math.reduce_std(self.returns)\n",
        "        return mean_return / (std_return + 1e-8)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.returns.assign(tf.zeros(shape=(0,), dtype=tf.float32))\n",
        "\n",
        "# ============ 构建数据集 ============\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
        "\n",
        "# ============ 初始化模型与训练组件 ============\n",
        "model = MLPNetwork(input_size=X_train.shape[1], hidden_size=[128, 64], dropout_rate=0.1)\n",
        "\n",
        "loss_object = corr_loss\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = InfoRatio(name='train_IR')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = InfoRatio(name='test_IR')\n",
        "\n",
        "# ============ 定义训练过程 ============\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy.update_state(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy.update_state(labels, predictions)\n",
        "\n",
        "# ============ 训练主循环 ============\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_state()\n",
        "    train_accuracy.reset_state()\n",
        "    test_loss.reset_state()\n",
        "    test_accuracy.reset_state()\n",
        "\n",
        "    for images, labels in train_ds:\n",
        "        train_step(images, labels)\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "\n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Loss: {train_loss.result():.4f}, '\n",
        "        f'Train IR: {train_accuracy.result():.4f}, '\n",
        "        f'Test Loss: {test_loss.result():.4f}, '\n",
        "        f'Test IR: {test_accuracy.result():.4f}'\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCWHDnwDLRTy",
        "outputId": "6a62745d-50d5-406f-f599-672bd61ae548"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-a191b49e37c5>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df.sort_values(by=['DATE', 'RIC', 'TIME'], inplace=True)\n",
            "<ipython-input-11-a191b49e37c5>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['TIMEID'] = train_df.groupby(['DATE', 'RIC']).cumcount()\n"
          ]
        }
      ]
    }
  ]
}